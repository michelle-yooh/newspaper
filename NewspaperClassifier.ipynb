{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection: BBC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained from http://mlg.ucd.ie/datasets/bbc.html\n",
    "- 2225 articles from BBC in five topical areas from 2004-2005\n",
    "- business, entertainment, politics, sport, tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'bbc-fulltext/bbc/'\n",
    "topics = {'business':510 , \n",
    "          'entertainment':386, \n",
    "          'politics':417, \n",
    "          'sport':511, \n",
    "          'tech':401}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(topics.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting words within a directory \n",
    "(Referred:https://www2.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from math import log\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop += ['said','also','u','would','one']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization (Lemmatizaiton and word count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    lowers = text.lower()\n",
    "    no_punct = lowers.translate(str.maketrans('','',string.punctuation))\n",
    "    tokens = word_tokenize(no_punct)\n",
    "    filtered1 = [token for token in tokens if token not in stop]\n",
    "    lem = [lmtzr.lemmatize(token) for token in filtered1]\n",
    "    filtered2 = [token for token in lem if token not in stop]\n",
    "    return filtered2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countWord(dir_name):\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    count = Counter()\n",
    "    for fname in os.listdir(dir_name):\n",
    "        with open(dir_name+'/'+fname,'r') as f:\n",
    "            words = preprocess(f.read())\n",
    "            count += Counter(words)\n",
    "            \"\"\"\n",
    "            file = f.read()\n",
    "            lowers = file.lower()\n",
    "            no_punct = lowers.translate(str.maketrans('','',string.punctuation))\n",
    "            tokens = word_tokenize(no_punct)\n",
    "            filtered1 = [token for token in tokens if token not in stop]\n",
    "            lem = [lmtzr.lemmatize(token) for token in filtered1]\n",
    "            filtered2 = [token for token in lem if token not in stop]\n",
    "            count += Counter(filtered2)\n",
    "            \"\"\"\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = {topic:countWord(data_dir+topic) for topic in topics.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_tfidf(counter_list):\n",
    "    # counter_list is a dictionary of string (topic name) and counter (counts) pair\n",
    "    return_list = {}\n",
    "    all_frequency = Counter()\n",
    "    for counter in counter_list.values():\n",
    "        all_frequency = all_frequency + counter\n",
    "    # compute tfidf for each topic\n",
    "    for topic in counter_list:\n",
    "        counter = counter_list[topic]\n",
    "        except_frequency = all_frequency - counter\n",
    "        \n",
    "        #compute tf\n",
    "        tf = {}\n",
    "        tf_N = sum(counter.values(),0.0)\n",
    "        for key in counter:\n",
    "            tf[key] = counter[key] / tf_N\n",
    "        \n",
    "        #compute idf\n",
    "        idf = {}\n",
    "        idf_N = sum(except_frequency.values(),0.0)\n",
    "        for key in except_frequency:\n",
    "            idf[key] = log(idf_N / except_frequency[key])\n",
    "        \n",
    "        tfidf = {}\n",
    "        for word in tf:\n",
    "            if word not in idf:\n",
    "                # the word only appears in this topic\n",
    "                continue\n",
    "                tfidf[word] = 1.0\n",
    "            else:\n",
    "                tfidf[word] = tf[word] * idf[word]\n",
    "\n",
    "        return_list[topic] = tfidf\n",
    "        \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = compute_tfidf(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business :\n",
      "year company firm market bank growth economy price oil share mr sale economic rate new analyst profit government last 2004 \n",
      "\n",
      "entertainment :\n",
      "film award best year music show star actor oscar band album song singer chart new director comedy nomination number first \n",
      "\n",
      "politics :\n",
      "mr labour party blair election government minister people lord brown mp say plan howard tax prime secretary chancellor conservative public \n",
      "\n",
      "sport :\n",
      "game england win player cup match champion first coach side rugby team world injury ireland club back time year last \n",
      "\n",
      "tech :\n",
      "people technology mobile user phone game software computer service digital net site pc new use online network could device gadget \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "for topic in topics.keys():\n",
    "    print(topic,\":\")\n",
    "    sorted_list = sorted(tfidf[topic].items(), key=operator.itemgetter(1),reverse=True)\n",
    "    toptwenty = sorted_list[:20]\n",
    "    print(' '.join([s[0] for s in toptwenty]),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These TF-IDF scores seem to represent each topic very well.\n",
    "\n",
    "Now, I will sum up the TF-IDF scores from training data to create a new metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_tfidf(text,tfidf):\n",
    "    words = preprocess(text)\n",
    "    metrics = {key: 0 for key in tfidf.keys()}\n",
    "    for word in words:\n",
    "        for topic in tfidf.keys():\n",
    "            if word in tfidf[topic]:\n",
    "                metrics[topic] += tfidf[topic][word]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metric(topic,tfidf):\n",
    "    topic_dir = data_dir + topic + \"/\"\n",
    "    result = {key: 0 for key in tfidf.keys()}\n",
    "    for fname in os.listdir(topic_dir):\n",
    "        with open(topic_dir+fname,'r') as f:\n",
    "            r = f.read()\n",
    "            metrics = sum_tfidf(r,tfidf)\n",
    "            for key in metrics:\n",
    "                result[key] += metrics[key]\n",
    "    denom = sum(result.values())\n",
    "    stnd_result = {key: round(result[key]/denom,2) for key in result}\n",
    "    return stnd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business\n",
      "{'business': 0.35, 'entertainment': 0.14, 'politics': 0.2, 'sport': 0.13, 'tech': 0.18}\n",
      "entertainment\n",
      "{'business': 0.14, 'entertainment': 0.38, 'politics': 0.15, 'sport': 0.15, 'tech': 0.17}\n",
      "politics\n",
      "{'business': 0.18, 'entertainment': 0.13, 'politics': 0.41, 'sport': 0.12, 'tech': 0.16}\n",
      "sport\n",
      "{'business': 0.14, 'entertainment': 0.17, 'politics': 0.15, 'sport': 0.38, 'tech': 0.16}\n",
      "tech\n",
      "{'business': 0.17, 'entertainment': 0.16, 'politics': 0.17, 'sport': 0.14, 'tech': 0.36}\n"
     ]
    }
   ],
   "source": [
    "for topic in topics.keys():\n",
    "    print(topic)\n",
    "    print(get_metric(topic,tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is in a good shape. The metrics for the correct classes are always greater than 0.35 and incorrect classes are always less than 0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
